import Foundation
import Speech

final class SpeechRecognizer: NSObject, ObservableObject, SFSpeechRecognizerDelegate, @unchecked Sendable {
    private var speechRecognizer: SFSpeechRecognizer!
    private var recognitionRequest: SFSpeechAudioBufferRecognitionRequest?
    private var recognitionTask: SFSpeechRecognitionTask?
    private let audioEngine = AVAudioEngine()
    
    @Published var transcript = ""
    private var isTranscribing = false
    private var audioDurationTimer: Timer?
    private var audioDurationLimit: Int = 2
    
    override init() {
        super.init()
        
        let rawLanguage = Locale.preferredLanguages.first ?? "en"
        let languageCode = Locale(identifier: rawLanguage).language.languageCode?.identifier ?? "en"
        let supportedLocales = SFSpeechRecognizer.supportedLocales()

        let matchedLocale = supportedLocales.first(where: {
            $0.language.languageCode?.identifier == languageCode
        }) ?? Locale(identifier: "en-US")

        speechRecognizer = SFSpeechRecognizer(locale: matchedLocale)
        speechRecognizer.delegate = self
    }
    
    // ìŒì„±ì¸ì‹ ì‹œì‘
    func startTranscribing() {
        guard !isTranscribing else { return }
          
          // ìŒì„± ì¸ì‹ ì‹œì‘ íŒë³„ í”„ë¡œí¼í‹° ìƒíƒœ ë³€ê²½
          isTranscribing = true
          
          // ì˜¤ë””ì˜¤ ì—”ì§„ì´ ì‹¤í–‰ ì¤‘ì´ë©´ ì¤‘ì§€í•˜ê³  ëª¨ë“  tapì„ ì œê±°
          if audioEngine.isRunning {
            audioEngine.stop()
            audioEngine.inputNode.removeTap(onBus: 0)
          }
          
          // ê¸°ì¡´ ì‹¤í–‰ëœ ìŒì„± ì¸ì‹ ì‘ì—…ì¸, recognitionTaskê°€ ìˆë‹¤ë©´ í•´ë‹¹ ì‘ì—… ì·¨ì†Œ
          recognitionTask?.cancel()
          recognitionTask = nil
          
          // ì˜¤ë””ì˜¤ ì„¸ì…˜ ì„¤ì • ë° í™œì„±í™”
          let audioSession = AVAudioSession.sharedInstance()
          do {
            try audioSession.setCategory(.record, mode: .measurement, options: .duckOthers)
            try audioSession.setActive(true, options: .notifyOthersOnDeactivation)
          } catch {
            print("ì˜¤ë””ì˜¤ ì„¸ì…˜ ì„¤ì • ì‹¤íŒ¨: \(error)")
            isTranscribing = false
            return
          }
          
          // ìŒì„± ì¸ì‹ ìš”ì²­ ìƒì„±
          recognitionRequest = SFSpeechAudioBufferRecognitionRequest()
          guard let recognitionRequest = recognitionRequest else {
            // ì„¤ì • ì¤‘ ì˜¤ë¥˜ ì‹œ ìŒì„± ì¸ì‹ ìƒíƒœ ë³€ê²½
            isTranscribing = false
            return
          }
          
          // ë¶€ë¶„ì  ê²°ê³¼ ë³´ê³  ì„¤ì •
          recognitionRequest.shouldReportPartialResults = true
          
          // ìŒì„± ì¸ì‹ ì‘ì—… ì„¤ì •
          recognitionTask = speechRecognizer.recognitionTask(with: recognitionRequest) { result, error in
            var isFinal = false
            
            if let result = result {
                let text = result.bestTranscription.formattedString
                
                if !text.isEmpty {
                    Task { @MainActor in
                        self.transcript = text
                        print("ğŸ¤ ì‹¤ì‹œê°„ ì¸ì‹ í…ìŠ¤íŠ¸: \(text)")
                    }
                }
                
                self.stopAudioDurationTimer()
                self.startAudioDurationTimer()
                isFinal = result.isFinal
            }
              
            if error != nil || isFinal {
                self.cleanup()
            }
          }
          
          // ì˜¤ë””ì˜¤ ì—”ì§„ì— tapì„ ì¶”ê°€
          let recordingFormat = audioEngine.inputNode.outputFormat(forBus: 0)
          audioEngine.inputNode.installTap(onBus: 0, bufferSize: 1024, format: recordingFormat) { buffer, _ in
            recognitionRequest.append(buffer)
          }
          
          // ì˜¤ë””ì˜¤ ì—”ì§„ ì‹œì‘
          do {
            try audioEngine.start()
          } catch {
            print("ì˜¤ë””ì˜¤ ì—”ì§„ ì‹œì‘ ì‹¤íŒ¨: \(error)")
            cleanup()
          }
    }
    
    private func startAudioDurationTimer() {
        audioDurationTimer = Timer.scheduledTimer(
            timeInterval: TimeInterval(self.audioDurationLimit),
            target: self,
            selector: #selector(timeOut),
            userInfo: nil,
            repeats: false
        )
    }
    
    private func stopAudioDurationTimer() {
        if audioDurationTimer != nil {
            audioDurationTimer?.invalidate()
            audioDurationTimer = nil
        }
    }
    
    @objc private func timeOut() {
        stopTranscribing()
   }
    
    // ìŒì„±ì¸ì‹ ì¢…ë£Œ
    func stopTranscribing() {
        recognitionTask?.cancel()
        cleanup()
    }
    
    private func cleanup() {
        if audioEngine.isRunning {
            audioEngine.stop()
            audioEngine.inputNode.removeTap(onBus: 0)
        }
        recognitionRequest?.endAudio()
        recognitionRequest = nil
        recognitionTask = nil
        isTranscribing = false
    }
}
